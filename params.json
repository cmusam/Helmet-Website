{
  "name": "Helmet",
  "tagline": "",
  "body": "# Final Report Draft (5/9)\r\nFinal Write Up (due Monday, May 9th, 11:59PM)\r\n\r\nYour proposal should include the following basic sections. Not all the sub-bullets apply to all projects, but they are given as examples/suggestions of issues to address. You are also encouraged to provide more detail if you wish. Note that some of the information in your final writeup can be pulled directly from your proposal if it is still accurate.\r\n\r\n## SUMMARY\r\nI implemented and parallelized selected machine learning functions and routines written in Swift 2.0 on OS X using Metal, _a low-level, low-overhead hardware-accelerated graphics and compute API_.\r\n\r\n## BACKGROUND\r\n### Sigmoid\r\n\r\n### Gradient descent\r\n### Stochastic Gradient descent\r\n### Convolution\r\n![](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)\r\n\r\n\r\nDescribe the algorithm, application, or system you parallelized in computer science terms. (Recall our discussion from the last day of class.) Figure(s) would be really useful here.\r\n\r\nWhat are the key data structures?\r\nWhat are the key operations on these data structures?\r\nWhat are the algorithm's inputs and outputs?\r\nWhat is the part that computationally expensive and could benefit from parallelization?\r\nBreak down the workload. Where are the dependencies in the program? How much parallelism is there? Is it data-parallel? Where is the locality? Is it amenable to SIMD execution?\r\n\r\n## APPROACH\r\nTell us how your implementation works. Your description should be sufficiently detailed to provide the course staff a basic understanding of your approach. Again, it might be very useful to include a figure here illustrating components of the system and/or their mapping to parallel hardware.\r\n\r\nDescribe the technologies used. What language/APIs? What machines did you target?\r\nDescribe how you mapped the problem to your target parallel machine(s). IMPORTANT: How do the data structures and operations you described in part 2 map to machine concepts like cores and threads. (or warps, thread blocks, gangs, etc.)\r\nDid you change the original serial algorithm to enable better mapping to a parallel machine?\r\nIf your project involved many iterations of optimization, please describe this process as well. What did you try that did not work? How did you arrive at your solution? The notes you've been writing throughout your project should be helpful here. Convince us you worked hard to arrive at a good solution.\r\nIf you started with an existing piece of code, please mention it (and where it came from) here.\r\n\r\n## RESULTS\r\nHow successful were you at achieving your goals? We expect results sections to differ from project to project, but we expect your evaluation to be very thorough (your project evaluation is a great way to demonstrate you understood topics from this course). Here are a few ideas:\r\n\r\nIf your project was optimizing an algorithm, please define how you measured performance. Is it wall-clock time? Speedup? An application specific rate? (e.g., moves per second, images/sec)\r\nPlease also describe your experimental setup. What were the size of the inputs? How were requests generated?\r\nProvide graphs of speedup or execute time. Please precisely define the configurations being compared. Is your baseline single-threaded CPU code? It is an optimized parallel implementation for a single CPU?\r\nRecall the importance of problem size. Is it important to report results for different problem sizes for your project? Do different workloads exhibit different execution behavior?\r\nIMPORTANT: What limited your speedup? Is it a lack of parallelism? (dependencies) Communication or synchronization overhead? Data transfer (memory-bound or bus transfer bound). Poor SIMD utilization due to divergence? As you try and answer these questions, we strongly prefer that you provide data and measurements to support your conclusions. If you are merely speculating, please state this explicitly. Performing a solid analysis of your implementation is a good way to pick up credit even if your optimization efforts did not yield the performance you were hoping for.\r\nDeeper analysis: Can you break execution time of your algorithm into a number of distinct components. What percentage of time is spent in each region? Where is there room to improve?\r\nWas your choice of machine target sound? (If you chose a GPU, would a CPU have been a better choice? Or vice versa.)\r\n\r\n## REFERENCES\r\nPlease provide a list of references used in the project.\r\n\r\n\r\n\r\n\r\n\r\n---\r\n---\r\n---\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Checkpoint (4/19)\r\n\r\n### Work I have completed so far\r\nHaving no previous experience in Swift, I familiarized myself with Swift and Objective C to prepare for this project. As a first step, I replicated the sequential versions assignment one programs in Swift. I plan to use these single core single thread performance as the benchmark for later improvements.\r\n\r\n### Work schedule\r\nThe original schedule was to complete the basic parallel primitives (map, reduce, scan, filter) by 4/15. Since learning Swift and setting up the appropriate environments took longer than expected, I have yet completed implementing them. \r\n\r\nYes, I still believe I will be able to produce all your deliverables. An updated and more refined schedule is as below. I plan to have intermediate updates to this webpage at each of the following dates.\r\n- 4/23 (Friday) fully set up Metal and test GPU computation\r\n- 4/26 (Tuesday) map, reduce\r\n- 4/30 (Friday) scan, filter\r\n- 5/3 (Tuesday) machine learning application start\r\n- 5/6 (Friday) machine learning application done\r\n\r\n### Presentation at parallelism competition\r\nGraphs showing (hopefully) a significant speedup using Swift on a common machine learning routine. Explain the motivation of the project, and possible applications of the Blade library.\r\n\r\n### Preliminary results\r\nI have set benchmarks by running assignment one programs using single core single thread environments. More results to follow once the primitives are implemented. \r\n\r\n### Concerns and unknowns\r\nFinding an appropriate dataset to apply machine learning algorithms using Blade. The dataset should be of an appropriate size. Also, I should ideally record a benchmark performance using a sequential algorithm.\r\n\r\n---\r\n---\r\n---\r\n\r\n# Proposal (4/1)\r\n\r\n### Summary\r\nI plan to implement a Swift 2.0 Library that allows efficient GPU parallel computations on Mac OS X using Metal. Compared to iOS devices, Macs have more powerful GPUs with larger on-device memories, creating greater potential for parallel computation.\r\n\r\n### Background\r\nIn December 2015, Swift was open sourced and is possibly on its way to become a mainstream programming language. At WWDC 2015, Apple announced support for Metal on OS X, unleashing more efficient computing possibilities for Mac OS applications.\r\n\r\nAlthough originally designed for iOS applications to realize fast real time graphic processing, one important feature of Metal is its integrated support for both graphics and compute operations. Therefore, fields requiring large scale computation such as deep learning can also benefit greatly from this library. \r\n\r\n### The Challenge\r\nBoth the Metal API and Swift 2.0 are relatively new. Support and documentation may therefore be limited. I expect more challenge to arise as I proceed with the project.\r\n\r\n### Resources\r\n- https://developer.apple.com/metal/\r\n- https://developer.apple.com/swift/resources/parall\r\n\r\n### Goals and Deliverables\r\nIf successful, I plan to deliver a set of common parallel primitives that can be used directly in Swift 2.0. To achieve speedup on parallelizable computations,   we expect users to have no knowledge of Metal or the GPU.\r\n\r\n### Platform Choice\r\n- Mac OS X El Capitan\r\n- Swift 2.0\r\n\r\n### Schedule\r\n- 4/1 Proposal\r\n- 4/8 Conduct research on and experimenting with Metal on Mac OS X.\r\n- 4/15 Implement fundamental GPU algorithms such as scan, sort, reduce, map.\r\n- 4/28 Evaluate and possibly improve the performance of existing code.\r\n- 5/9 Deadline",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}